dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- max(round(N / 100), 10) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
# Sampling schemes.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_r", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "d$^*_{\\mathrm{ER}}$", "d$^*_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
r = c(rep(NA, 7), 0.5, 5, 10))
L <- list(NULL, c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
params$s <- 1:nrow(params)
library("expm")
library("Matrix")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/opt_sampling_scheme.R")
source("Rscript/Phi.R")
load("Data/VirtSim.R")
df$caseID <- as.numeric(df$caseID)
maximpact <- df %>%
group_by(caseID) %>%
summarise(max_impact_speed = max(impact_speed0, na.rm = TRUE), .groups = "keep") %>%
ungroup() %>%
dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- max(round(N / 100), 10) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
# Sampling schemes.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_r", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "d$^*_{\\mathrm{ER}}$", "d$^*_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
r = c(rep(NA, 7), 0.5, 5, 10))
L <- list(NULL, c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
params$s <- 1:nrow(params)
params <- crossing(design = c("PO-WR", "PO-WOR"), params, niter = NA, status = NA, A_eff = NA, c1_eff = NA, c2_eff = NA, D_eff = NA, dER_eff = NA, dS_eff = NA, E_eff = NA, Phi05_eff = NA, Phi5_eff = NA, Phi10_eff = NA) %>%
arrange(desc(design), s)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
opt <- opt_sampling_scheme(n, G, H, w, crit = params$crit[i], L = params$L[[i]], r = params$r[i], design = params$design[i])
params$niter[i] <- opt$niter
params$status[i] <- opt$status
params$A_eff[i] <- Phi(opt$Gamma, crit = "A")
params$c1_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[2]])
params$c2_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[3]])
params$D_eff[i] <- Phi(opt$Gamma, crit = "D")
params$dER_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[5]])
params$dS_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[6]])
params$E_eff[i] <- Phi(opt$Gamma, crit = "E")
params$Phi05_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 0.5)
params$Phi5_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 5)
params$Phi10_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 10)
}
Sys.time()
t0 <- Sys.time()
t1 <- Sys.time()
t1 - t0
as.numeric(t1 - t0)
source("~/GitHub/OSD/RScript/opt_sampling_scheme.R")
# Sampling schemes.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_r", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "d$^*_{\\mathrm{ER}}$", "d$^*_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
r = c(rep(NA, 7), 0.5, 5, 10))
L <- list(NULL, c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
params$s <- 1:nrow(params)
params <- crossing(design = c("PO-WR", "PO-WOR"), params, niter = NA, status = NA, A_eff = NA, c1_eff = NA, c2_eff = NA, D_eff = NA, dER_eff = NA, dS_eff = NA, E_eff = NA, Phi05_eff = NA, Phi5_eff = NA, Phi10_eff = NA) %>%
arrange(desc(design), s)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
opt <- opt_sampling_scheme(n, G, H, w, crit = params$crit[i], L = params$L[[i]], r = params$r[i], design = params$design[i])
params$niter[i] <- opt$niter
params$status[i] <- opt$status
params$A_eff[i] <- Phi(opt$Gamma, crit = "A")
params$c1_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[2]])
params$c2_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[3]])
params$D_eff[i] <- Phi(opt$Gamma, crit = "D")
params$dER_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[5]])
params$dS_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[6]])
params$E_eff[i] <- Phi(opt$Gamma, crit = "E")
params$Phi05_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 0.5)
params$Phi5_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 5)
params$Phi10_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 10)
}
source("~/GitHub/OSD/RScript/opt_sampling_scheme.R")
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
opt <- opt_sampling_scheme(n, G, H, w, crit = params$crit[i], L = params$L[[i]], r = params$r[i], design = params$design[i])
params$niter[i] <- opt$niter
params$status[i] <- opt$status
params$A_eff[i] <- Phi(opt$Gamma, crit = "A")
params$c1_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[2]])
params$c2_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[3]])
params$D_eff[i] <- Phi(opt$Gamma, crit = "D")
params$dER_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[5]])
params$dS_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[6]])
params$E_eff[i] <- Phi(opt$Gamma, crit = "E")
params$Phi05_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 0.5)
params$Phi5_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 5)
params$Phi10_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 10)
}
# Relative efficiencies.
res <- params %>%
group_by(design) %>%
mutate(A_eff = min(A_eff) / A_eff,
c1_eff = min(c1_eff) / c1_eff,
c2_eff = min(c2_eff) / c2_eff,
D_eff = min(D_eff) / D_eff,
E_eff = min(E_eff) / E_eff,
dER_eff = min(dER_eff) / dER_eff,
dS_eff = min(dS_eff) / dS_eff,
Phi05_eff = min(Phi05_eff) / Phi05_eff,
Phi5_eff = min(Phi5_eff) / Phi5_eff,
Phi10_eff = min(Phi10_eff) / Phi10_eff) %>%
mutate(niter_s = ifelse(status == 0, sprintf("%.0f", niter), "Did not converge")) %>%
ungroup() %>%
dplyr::select(design, crit, name, niter, niter_s, everything())
# If optimal sampling scheme could not be found.
for ( i in 1:nrow(res) ) {
if ( res$niter_s[i] == "Did not converge") {
res[i, 10:ncol(res)] <- NA
if ( res$crit[i] == "E" ) {
res$E_eff[which(res$design == res$design[i])] <- NA
} else if ( res$crit[i] == "Phi_r" & res$r[i] == 5 ) {
res$Phi5_eff[which(res$design == res$design[i])] <- NA
} else if ( res$crit[i] == "Phi_r" & res$r[i] == 10 ) {
res$Phi10_eff[which(res$design == res$design[i])] <- NA
}
}
}
# Format cells.
res %<>% mutate(across(contains("eff"), fmt))
# Format cells.
res <- res %>% mutate(across(contains("eff"), fmt))
# Write xtable to file.
res %>%
filter(design == "PO-WR") %>%
dplyr::select(name, niter_s, A_eff, c1_eff, c2_eff, D_eff, dER_eff, Phi5_eff) %>%
dplyr::rename("Optimality criterion" = name,
"No. iterations needed for convergence" = niter_s,
"A-eff" = A_eff,
"c$_{(1,0)}$-eff" = c1_eff,
"c$_{(0,1)}$-eff" = c2_eff,
"D-eff" = D_eff,
"d$^*_{\\mathrm{ER}}$-eff"  = dER_eff,
"$\\Phi_5$-eff" = Phi5_eff) %>%
xtable(caption = "Evaluation of sampling schemes and optimality criteria for estimating the baseline impact speed distribution, assuming a log-normal model. \\textit{eff = relative efficiency.}",
label = "tab:baseline_impact_speed",
align = c("lp{2.75cm}R{3.125cm}R{1.1cm}R{1.3cm}R{1.3cm}R{1.1cm}R{1.2cm}R{1.2cm}")) %>%
print(caption.placement = "top",
hline.after = c(0, nrow(.)),
include.rownames = FALSE,
sanitize.text.function = function(x) x,
table.placement = "htb!",
file = "Tables/tab2.tex")
# AEB vs. manual baseline driving. ----
cat("\n------------------ AEB vs. manual baseline driving ------------------n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As matrix.
Y <- data %>%
dplyr::select(impact_speed_reduction, injury_risk_reduction, crash_avoidance) %>%
as.matrix()
N <- nrow(data) # Full-data size.
n <- max(round(N / 100), 10) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
theta0 <- colSums(w * Y) / sum(w) # Full-data parameter.
G <- t(-w * t(t(Y) - theta0)) # Gradients.
H <- diag(sum(w), length(theta0)) # Hessian.
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:ncol(G) ) {
V <- V + tcrossprod(G[, i])
}
# Sampling schemes.
params <- tibble(crit = c("A", rep("c", 3), "D", rep("L", 2), "E", rep("Phi_r", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0,0)\\T$", "c, $\\mathbf{c} = (0,1,0)\\T$", "c, $\\mathbf{c} = (0,0,1)\\T$", "D", "d$^*_{\\mathrm{ER}}$", "d$^*_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
r = c(rep(NA, 8), 0.5, 5, 10))
L <- list(NULL, c(1, 0, 0), c(0, 1, 0), c(0, 0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
params$s <- 1:nrow(params)
params <- crossing(design = c("PO-WR", "PO-WOR"), params, niter = NA, status = NA, A_eff = NA, c1_eff = NA, c2_eff = NA, c3_eff = NA, D_eff = NA, dER_eff = NA, dS_eff = NA, E_eff = NA, Phi05_eff = NA, Phi5_eff = NA, Phi10_eff = NA) %>%
arrange(desc(design), s)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
opt <- opt_sampling_scheme(n, G, H, w, crit = params$crit[i], L = params$L[[i]], r = params$r[i], design = params$design[i])
params$niter[i] <- opt$niter
params$status[i] <- opt$status
params$A_eff[i] <- Phi(opt$Gamma, crit = "A")
params$c1_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[2]])
params$c2_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[3]])
params$c3_eff[i] <- Phi(opt$Gamma, crit = "c", L = L[[4]])
params$D_eff[i] <- Phi(opt$Gamma, crit = "D")
params$dER_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[6]])
params$dS_eff[i] <- Phi(opt$Gamma, crit = "L", L = L[[7]])
params$E_eff[i] <- Phi(opt$Gamma, crit = "E")
params$Phi05_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 0.5)
params$Phi5_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 5)
params$Phi10_eff[i] <- Phi(opt$Gamma, crit = "Phi_r", r = 10)
}
# Relative efficiencies.
res <- params %>%
group_by(design) %>%
mutate(A_eff = min(A_eff) / A_eff,
c1_eff = min(c1_eff) / c1_eff,
c2_eff = min(c2_eff) / c2_eff,
c3_eff = min(c3_eff) / c3_eff,
D_eff = min(D_eff) / D_eff,
E_eff = min(E_eff) / E_eff,
dER_eff = min(dER_eff) / dER_eff,
dS_eff = min(dS_eff) / dS_eff,
Phi05_eff = min(Phi05_eff) / Phi05_eff,
Phi5_eff = min(Phi5_eff) / Phi5_eff,
Phi10_eff = min(Phi10_eff) / Phi10_eff) %>%
mutate(niter_s = ifelse(status == 0, sprintf("%.0f", niter), "Did not converge")) %>%
ungroup() %>%
dplyr::select(design, crit, name, niter, niter_s, everything())
# If optimal sampling scheme could not be found.
for ( i in 1:nrow(res) ) {
if ( res$niter_s[i] == "Did not converge") {
res[i, 10:ncol(res)] <- NA
if ( res$crit[i] == "E" ) {
res$E_eff[which(res$design == res$design[i])] <- NA
} else if ( res$crit[i] == "Phi_r" & res$r[i] == 5 ) {
res$Phi5_eff[which(res$design == res$design[i])] <- NA
} else if ( res$crit[i] == "Phi_r" & res$r[i] == 10 ) {
res$Phi10_eff[which(res$design == res$design[i])] <- NA
}
}
}
Matrix::determinant()
?Matrix::determinant
Matrix::determinant
?Matrix::determinant
?determinant
source("~/GitHub/OSD/RScript/figures.R")
source("~/GitHub/OSD/RScript/figures.R")
source("~/GitHub/OSD/RScript/figures.R")
source("~/GitHub/OSD/RScript/figures.R")
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
# Clean up. ----
rm(list = ls())
cat("\14")
library("expm")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/optimise_ss.R")
source("Rscript/Phi.R")
source("Rscript/acov.R")
source("Rscript/optimise_ss.R")
source("Rscript/Phi.R")
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
# Clean up. ----
rm(list = ls())
cat("\14")
# Load packages. ----
library("expm")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/Lopt.R")
source("Rscript/Phi.R")
source("Rscript/Phiopt.R")
# Prepare data. ----
load("Data/VirtSim.R")
df$caseID <- as.numeric(df$caseID)
maximpact <- df %>%
group_by(caseID) %>%
summarise(max_impact_speed = max(impact_speed0, na.rm = TRUE), .groups = "keep") %>%
ungroup() %>%
dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- max(round(N / 2), 10) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
n
source("~/GitHub/OSD/Rscript/main.R")
source("~/GitHub/OSD/Rscript/main.R")
0.004 + 365
0.004 * 365
0.006 * 365
x <- 1
2^2 / 2^4
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
source('~/GitHub/OSD/RScript/main.R')
sessionInfo()
print(sessinInfo())
print(sessionInfo())
sink("session_info.txt")
print(sessionInfo())
sink()
Sys.info()
sessionInfo()
install.packages("benchmarkme")
library("benchmarkme")
get_cpu()
get_ram()
print(benchmarkme::get_cpu())
print(benchmarkme::get_ram())
library("benchmarkme")
get_r_version
get_r_version()
get_sys_details
get_sys_details()
install.packages("sfsmisc")
library("sfsmisc")
Sys.cpuinfo
Sys.cpuinfo()
Sys.cpuinfo()
library("sfsmisc")
Sys.cpuinfo()
Sys.inf()
Sys.info()
print(get_cpu())
?get_cpu
?get_ram()
benchmarkme::get_platform_info()
benchmarkme::get_available_benchmarks()
benchmarkme::get_sys_details()
print(get_cpu())
print(get_ram())
sink("session_info.txt")
print(sessionInfo())
print(get_cpu())
print(get_ram())
sink()
sink("session_info.txt")
cat("Computer Info\n")
print(get_cpu())
print(get_ram())
cat("\n\nR Session Info\n")
print(sessionInfo())
sink()
sink("session_info.txt")
cat("CPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
cat("\n\nR Session Info\n")
print(sessionInfo())
sink()
sink("session_info.txt")
cat("\n\nR Session Info\n")
print(sessionInfo())
cat("CPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
sink("session_info.txt")
cat("\n\nR Session Info\n")
print(sessionInfo())
cat("CPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
sink("session_info.txt")
cat("R Session Info\n")
print(sessionInfo())
cat("\n\nCPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
