cat("\n\nR Session Info\n")
print(sessionInfo())
cat("CPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
sink("session_info.txt")
cat("R Session Info\n")
print(sessionInfo())
cat("\n\nCPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
source('~/GitHub/OSD/RScript/main.R')
plot(1:10)
sessionInfo()
plot(1:10)
source("~/GitHub/OSD/RScript/main.R")
source("~/GitHub/OSD/RScript/main.R")
citation()
source("~/GitHub/OSD/RScript/main.R")
################################################################################
#
# File name: main.R
#
# Author: Henrik Imberg
#
# Last edited: 2023-03-17
#
# Description: Main function for the experiments in Section 6.
#
# INPUT: Virtual simulation data stored in the Data folder.
#
# OUTPUT: is stored in the Tables folder.
#
################################################################################
# Clean up. ----
rm(list = ls())
cat("\14")
# Load packages. ----
library("benchmarkme")
library("expm")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/lopt.R")
source("Rscript/Phi.R")
source("Rscript/phiopt.R")
# Print session info. ----
sink("session_info.txt")
cat("R Session Info\n")
print(sessionInfo())
cat("\n\nCPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
# Prepare data. ----
load("Data/VirtSim.R")
df$caseID <- as.numeric(df$caseID)
maximpact <- df %>%
group_by(caseID) %>%
summarise(max_impact_speed = max(impact_speed0, na.rm = TRUE), .groups = "keep") %>%
ungroup() %>%
dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", "nreps", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- round(N / 100) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
# Parameters.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_s", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "$d_{\\mathrm{ER}}$", "$d_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
s = c(rep(NA, 7), 0.5, 5, 10),
design = "PO-WR")
L <- list(diag(ncol(H)), c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
# To store results.
res <- add_column(params, niter = NA_real_, t = NA_real_, status = NA_real_,
A_eff = NA_real_, c1_eff = NA_real_, c2_eff = NA_real_,
D_eff = NA_real_, dER_eff = NA_real_, dS_eff = NA_real_, E_eff = NA_real_,
Phi05_eff = NA_real_, Phi5_eff = NA_real_, Phi10_eff = NA_real_)
i <- 1
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
source("~/GitHub/OSD/RScript/lopt.R")
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
source("~/GitHub/OSD/RScript/lopt.R")
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
source("~/GitHub/OSD/RScript/lopt.R")
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
source("~/GitHub/OSD/RScript/lopt.R")
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], s = params$s[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 10)
}
source("~/GitHub/OSD/RScript/phiopt.R")
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], s = params$s[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 10)
}
n <- 40000
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], s = params$s[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 10)
}
n <- 1
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], s = params$s[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_s", s = 10)
}
source("~/GitHub/OSD/RScript/main.R")
source("~/GitHub/OSD/RScript/main.R")
source("~/GitHub/OSD/RScript/main.R")
# Clean up. ----
rm(list = ls())
cat("\14")
# Load packages. ----
library("benchmarkme")
library("expm")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/lopt.R")
source("Rscript/Phi.R")
source("Rscript/phiopt.R")
# Print session info. ----
sink("session_info.txt")
cat("R Session Info\n")
print(sessionInfo())
cat("\n\nCPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
# Prepare data. ----
load("Data/VirtSim.R")
df$caseID <- as.numeric(df$caseID)
maximpact <- df %>%
group_by(caseID) %>%
summarise(max_impact_speed = max(impact_speed0, na.rm = TRUE), .groups = "keep") %>%
ungroup() %>%
dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", "nreps", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- round(N / 100) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
# Parameters.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_q", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "$d_{\\mathrm{ER}}$", "$d_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
q = c(rep(NA, 7), 0.5, 5, 10),
design = "PO-WR")
L <- list(diag(ncol(H)), c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
# To store results.
res <- add_column(params, niter = NA_real_, t = NA_real_, status = NA_real_,
A_eff = NA_real_, c1_eff = NA_real_, c2_eff = NA_real_,
D_eff = NA_real_, dER_eff = NA_real_, dS_eff = NA_real_, E_eff = NA_real_,
Phi05_eff = NA_real_, Phi5_eff = NA_real_, Phi10_eff = NA_real_)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], q = params$q[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 10)
}
# Relative efficiencies.
res <- res %>%
mutate(A_eff = min(A_eff) / A_eff,
c1_eff = min(c1_eff) / c1_eff,
c2_eff = min(c2_eff) / c2_eff,
D_eff = min(D_eff) / D_eff,
E_eff = min(E_eff) / E_eff,
dER_eff = min(dER_eff) / dER_eff,
dS_eff = min(dS_eff) / dS_eff,
Phi05_eff = min(Phi05_eff) / Phi05_eff,
Phi5_eff = min(Phi5_eff) / Phi5_eff,
Phi10_eff = min(Phi10_eff) / Phi10_eff) %>%
mutate(niter_s = ifelse(status == 1, "Diverged", sprintf("%.0f", niter)),
niter_s = ifelse(status == 2, "Did not converge", niter_s),
niter_s = ifelse(niter_s == "NA", "", niter_s)) %>%
dplyr::select(crit, name, niter, niter_s, t, everything())
names(res)
source("~/GitHub/OSD/RScript/main.R")
# Clean up. ----
rm(list = ls())
cat("\14")
# Load packages. ----
library("benchmarkme")
library("expm")
library("sampling")
library("tidyverse")
library("xtable")
source("Rscript/acov.R")
source("Rscript/fmt.R")
source("Rscript/lopt.R")
source("Rscript/Phi.R")
source("Rscript/phiopt.R")
# Print session info. ----
sink("session_info.txt")
cat("R Session Info\n")
print(sessionInfo())
cat("\n\nCPU Info\n")
print(get_cpu())
cat("\n\nRAM\n")
print(get_ram())
sink()
# Prepare data. ----
load("Data/VirtSim.R")
df$caseID <- as.numeric(df$caseID)
maximpact <- df %>%
group_by(caseID) %>%
summarise(max_impact_speed = max(impact_speed0, na.rm = TRUE), .groups = "keep") %>%
ungroup() %>%
dplyr::select(caseID, max_impact_speed)
VSdata <- df %>%
dplyr::rename("OEOFF" = eoff,
"prob" = eoff_acc_prob) %>%
mutate(dec = -acc,
crash0 = as.numeric(impact_speed0 > 0),
crash1 = as.numeric(impact_speed1 > 0),
impact_speed_reduction = impact_speed0 - impact_speed1,
injury_risk_reduction = injury_risk0 - injury_risk1,
crash_avoidance = (1 - crash1) * crash0) %>%
dplyr::select(caseID, OEOFF, dec, everything(), -acc) %>%
left_join(maximpact, by = "caseID")
# Baseline impact speed distribution. ----
cat("\n------------------ Baseline impact speed distribution ------------------\n\n")
# Clean up.
rm(list = setdiff(ls(), c("VSdata", "nreps", lsf.str())))
# Data.
data <- VSdata %>%
filter(crash0 == 1)
# As vector.
y <- data$impact_speed0
logy <- log(data$impact_speed0)
N <- nrow(data) # Full-data size.
n <- round(N / 100) # Subsample size.
w <- with(data, crash0 * prob) # Observation weights.
# Full-data parameter.
theta0 <- c(weighted.mean(logy, w), sqrt(cov.wt(matrix(logy, ncol = 1), w, method = "ML")$cov))
# Gradients.
grads <- function(theta0, y, w = rep(1, nrow(y))) {
Z <- (log(y) - theta0[1]) / theta0[2]
dldMu <- - w * Z / theta0[2]
dldSig <- - w * (Z^2 - 1) / theta0[2]
return(rbind(dldMu, dldSig))
}
G <- grads(theta0, y, w)
# Hessian.
hess <- function(theta0, y, w) {
d1 <- sum(w)
return(diag(sum(w) * c(1, 2)) / theta0[2]^2)
}
H <- hess(theta0, y, w)
# V-matrix.
V <- matrix(0, nrow(H), ncol(H))
for ( i in 1:nrow(G) ) {
V <- V + tcrossprod(G[, i])
}
# Parameters.
params <- tibble(crit = c("A", rep("c", 2), "D", rep("L", 2), "E", rep("Phi_q", 3)),
name = c("A", "c, $\\mathbf{c} = (1,0)\\T$", "c, $\\mathbf{c} = (0,1)\\T$", "D", "$d_{\\mathrm{ER}}$", "$d_{\\mathrm{S}}$", "E", "$\\Phi_{0.5}$", "$\\Phi_5$", "$\\Phi_{10}$"),
q = c(rep(NA, 7), 0.5, 5, 10),
design = "PO-WR")
L <- list(diag(ncol(H)), c(1, 0), c(0, 1), NULL, sqrtm(H), H %*% solve(sqrtm(V)), NULL, NULL, NULL, NULL)
params$L <- L
# To store results.
res <- add_column(params, niter = NA_real_, t = NA_real_, status = NA_real_,
A_eff = NA_real_, c1_eff = NA_real_, c2_eff = NA_real_,
D_eff = NA_real_, dER_eff = NA_real_, dS_eff = NA_real_, E_eff = NA_real_,
Phi05_eff = NA_real_, Phi5_eff = NA_real_, Phi10_eff = NA_real_)
# Find optimal sampling schemes and evaluate performance analytically.
for ( i in 1:nrow(params) ) {
if ( params$crit[i] %in% c("A", "c", "L") ) {
opt <- lopt(n, G, H, L = params$L[[i]], design = params$design[i], print_level = 1)
opt$status <- 0
Gamma <- acov(mu = opt$mu, G, H, params$design[i])
} else {
opt <- phiopt(n, G, H, crit = params$crit[i],
L = params$L[[i]], q = params$q[i], design = params$design[i],
print_level = 1)
Gamma <- opt$Gamma
}
res$niter[i] <- opt$niter
res$t[i] <- opt$elapsed
res$status[i] <- opt$status
res$A_eff[i] <- Phi(Gamma, crit = "A")
res$c1_eff[i] <- Phi(Gamma, crit = "c", L = L[[2]])
res$c2_eff[i] <- Phi(Gamma, crit = "c", L = L[[3]])
res$D_eff[i] <- Phi(Gamma, crit = "D")
res$dER_eff[i] <- Phi(Gamma, crit = "L", L = L[[5]])
res$dS_eff[i] <- Phi(Gamma, crit = "L", L = L[[6]])
res$E_eff[i] <- Phi(Gamma, crit = "E")
res$Phi05_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 0.5)
res$Phi5_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 5)
res$Phi10_eff[i] <- Phi(Gamma, crit = "Phi_q", q = 10)
}
# Relative efficiencies.
res <- res %>%
mutate(A_eff = min(A_eff) / A_eff,
c1_eff = min(c1_eff) / c1_eff,
c2_eff = min(c2_eff) / c2_eff,
D_eff = min(D_eff) / D_eff,
E_eff = min(E_eff) / E_eff,
dER_eff = min(dER_eff) / dER_eff,
dS_eff = min(dS_eff) / dS_eff,
Phi05_eff = min(Phi05_eff) / Phi05_eff,
Phi5_eff = min(Phi5_eff) / Phi5_eff,
Phi10_eff = min(Phi10_eff) / Phi10_eff) %>%
mutate(niter_s = ifelse(status == 1, "Diverged", sprintf("%.0f", niter)),
niter_s = ifelse(status == 2, "Did not converge", niter_s),
niter_s = ifelse(niter_s == "NA", "", niter_s)) %>%
dplyr::select(crit, name, niter, niter_s, t, everything())
source("~/GitHub/OSD/RScript/main.R")
source("~/GitHub/OSD/RScript/main.R")
source("~/GitHub/OSD/RScript/main.R")
